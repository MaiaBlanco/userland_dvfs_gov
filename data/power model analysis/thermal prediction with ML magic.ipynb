{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# import scikitlearn\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Local includes:\n",
    "sys.path.append(\"../../src/\")\n",
    "import therm_params as tp\n",
    "from power_model import (\n",
    "    leakagePower,\n",
    "    peripheral_power,\n",
    "    board_power\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blackscholes_files = glob.glob(\"../blackscholes_benchmarking/*.csv\")\n",
    "bodytrack_files = glob.glob(\"../bodytrack_benchmarking/*.csv\")\n",
    "random_data = [\"../random_test.csv\"]\n",
    "files = random_data#blackscholes_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = \"time\twatts\tw_leak\tw_dyn\tw_periph\tusage_c0\tusage_c1\tusage_c2\tusage_c3\tusage_c4\tusage_c5\tusage_c6\tusage_c7\ttemp4\ttemp5\ttemp6\ttemp7\ttemp_gpu\tfreq_little_cluster\tfreq_big_cluster\tfreq_gpu\tfreq_mem,\tvolts_little_cluster\tvolts_big_cluster\tvolts_gpu\tvolts_mem\".split('\\t')\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, index_col=False, header=0, sep='\\t', usecols=header)\n",
    "    # Drop where watts <= 0:\n",
    "    df = df.loc[df.watts > 0]\n",
    "    # Need to add a column for each entry that is the next set of thermal values\n",
    "    # if there is no next row, then the current row should be discarded (hence last row)\n",
    "    # Set initial values to NAN\n",
    "    df['next_t4'] = np.nan\n",
    "    df['next_t5'] = np.nan\n",
    "    df['next_t6'] = np.nan\n",
    "    df['next_t7'] = np.nan\n",
    "    df['next_watts'] = np.nan\n",
    "#     indices_to_drop = []\n",
    "    for index,row in df.iterrows():   \n",
    "        if index < len(df.index)-1:\n",
    "            df.at[index, 'next_t4'] = df.loc[index+1, 'temp4']\n",
    "            df.at[index, 'next_t5'] = df.loc[index+1, 'temp5']\n",
    "            df.at[index, 'next_t6'] = df.loc[index+1, 'temp6']\n",
    "            df.at[index, 'next_t7'] = df.loc[index+1, 'temp7']\n",
    "            df.at[index, 'next_watts'] = df.loc[index+1, 'watts']\n",
    "        elif index < len(df.index):\n",
    "            # drop the current row\n",
    "#             indices_to_drop.append(index)\n",
    "            df.drop(df.index[[index]], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat(df_list, ignore_index=True)\n",
    "# Drop all measurements where watts <= 0:\n",
    "data = data.loc[data.watts > 0]\n",
    "# fill in the potentially missing voltage values\n",
    "data.volts_big_cluster = data.freq_big_cluster.map(lambda x: tp.big_f_to_v[float(x)/1000000000])\n",
    "data.volts_little_cluster = data.freq_little_cluster.map(lambda x: tp.little_f_to_v[float(x)/1000000000])\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'watts', 'w_leak', 'w_dyn', 'w_periph', 'usage_c0', 'usage_c1',\n",
       "       'usage_c2', 'usage_c3', 'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\n",
       "       'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu', 'freq_little_cluster',\n",
       "       'freq_big_cluster', 'freq_gpu', 'freq_mem,', 'volts_little_cluster',\n",
       "       'volts_big_cluster', 'volts_gpu', 'volts_mem', 'next_t4', 'next_t5',\n",
       "       'next_t6', 'next_t7', 'next_watts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get just the data to be used for train and test:\n",
    "XY = data[[\n",
    "            # Inputs:\n",
    "            'watts', 'usage_c0', 'usage_c1', 'usage_c2', 'usage_c3', \\\n",
    "            'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\\\n",
    "            'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu',\\\n",
    "            'freq_big_cluster', 'freq_little_cluster',\\\n",
    "            'volts_big_cluster', 'volts_little_cluster',\\\n",
    "            # Expected outputs:\n",
    "            'next_t4', 'next_t5', 'next_t6', 'next_t7', 'next_watts',\\\n",
    "            # Keep the timestamp for later plotting:\n",
    "            'time'\\\n",
    "            ]]\n",
    "XY = XY.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an MLP regression model to predict each temperature (for big cores)\n",
    "# and power for the whole board:\n",
    "# Parameters:\n",
    "activator = 'relu'\n",
    "alpha_r = .1\n",
    "hidden_layer_sizes = (100, 60, 10)\n",
    "maximum_iterations = 200\n",
    "# The model:\n",
    "TPM = MLPRegressor(activation=activator, alpha=alpha_r,\\\n",
    "                   hidden_layer_sizes=hidden_layer_sizes,\\\n",
    "                  random_state = 45, max_iter=maximum_iterations)\n",
    "X = XY[ [\n",
    "            # Inputs:\n",
    "            'watts', 'usage_c0', 'usage_c1', 'usage_c2', 'usage_c3', \\\n",
    "            'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\\\n",
    "            'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu',\\\n",
    "            'freq_big_cluster', 'freq_little_cluster',\\\n",
    "            'volts_big_cluster', 'volts_little_cluster' ] ].as_matrix()\n",
    "\n",
    "Y = XY[ ['next_t4', 'next_t5', 'next_t6', 'next_t7', 'next_watts'] ].as_matrix()\n",
    "\n",
    "# # Create training and test sets:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model:\n",
    "TPM = TPM.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each of the models on test data:\n",
    "Pt = TPM.predict(X_train)\n",
    "Pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run each of the models on test data:\n",
    "P = TPM.predict(X_test)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score:\n",
    "R = TPM.score(X_test, P)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train - Pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
