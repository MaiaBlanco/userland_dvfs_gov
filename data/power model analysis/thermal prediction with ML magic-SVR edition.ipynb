{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# import scikitlearn\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Local includes:\n",
    "sys.path.append(\"../../src/\")\n",
    "import therm_params as tp\n",
    "from power_model import (\n",
    "    leakagePower,\n",
    "    peripheral_power,\n",
    "    board_power\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackscholes_files = glob.glob(\"../blackscholes_benchmarking/*.csv\")\n",
    "bodytrack_files = glob.glob(\"../bodytrack_benchmarking/*.csv\")\n",
    "# random_data = [\"../random_test.csv\"]\n",
    "random_data = [\"../bodytrack_benchmarking/xu4_random_loads_4_1_2018.csv\"]\n",
    "files = random_data#blackscholes_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"time\twatts\tw_leak\tw_dyn\tw_periph\tusage_c0\tusage_c1\tusage_c2\tusage_c3\tusage_c4\tusage_c5\tusage_c6\tusage_c7\ttemp4\ttemp5\ttemp6\ttemp7\ttemp_gpu\tfreq_little_cluster\tfreq_big_cluster\tfreq_gpu\tfreq_mem,\tvolts_little_cluster\tvolts_big_cluster\tvolts_gpu\tvolts_mem\".split('\\t')\n",
    "   \n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, index_col=False, header=0, sep='\\t', usecols=header)\n",
    "    # Drop where watts <= 0:\n",
    "    df = df.loc[df.watts > 0]\n",
    "    # Need to add a column for each entry that is the next set of thermal values\n",
    "    # if there is no next row, then the current row should be discarded (hence last row)\n",
    "    # Set initial values to NAN\n",
    "    df['next_t4'] = np.nan\n",
    "    df['next_t5'] = np.nan\n",
    "    df['next_t6'] = np.nan\n",
    "    df['next_t7'] = np.nan\n",
    "    df['next_watts'] = np.nan\n",
    "#     indices_to_drop = []\n",
    "    for index,row in df.iterrows():   \n",
    "        if index < len(df.index)-1:\n",
    "            df.at[index, 'next_t4'] = df.loc[index+1, 'temp4']\n",
    "            df.at[index, 'next_t5'] = df.loc[index+1, 'temp5']\n",
    "            df.at[index, 'next_t6'] = df.loc[index+1, 'temp6']\n",
    "            df.at[index, 'next_t7'] = df.loc[index+1, 'temp7']\n",
    "            df.at[index, 'next_watts'] = df.loc[index+1, 'watts']\n",
    "        elif index < len(df.index):\n",
    "            # drop the current row\n",
    "#             indices_to_drop.append(index)\n",
    "            df.drop(df.index[[index]], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(df_list, ignore_index=True)\n",
    "# Drop all measurements where watts <= 0:\n",
    "data = data.loc[data.watts > 0]\n",
    "# fill in the potentially missing voltage values\n",
    "data.volts_big_cluster = data.freq_big_cluster.map(lambda x: tp.big_f_to_v[float(x)/1000000000])\n",
    "data.volts_little_cluster = data.freq_little_cluster.map(lambda x: tp.little_f_to_v[float(x)/1000000000])\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'watts', 'w_leak', 'w_dyn', 'w_periph', 'usage_c0', 'usage_c1',\n",
       "       'usage_c2', 'usage_c3', 'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\n",
       "       'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu', 'freq_little_cluster',\n",
       "       'freq_big_cluster', 'freq_gpu', 'freq_mem,', 'volts_little_cluster',\n",
       "       'volts_big_cluster', 'volts_gpu', 'volts_mem', 'next_t4', 'next_t5',\n",
       "       'next_t6', 'next_t7', 'next_watts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the data to be used for train and test:\n",
    "XY = data.loc[:,[\n",
    "            # Inputs:\n",
    "            'watts', 'usage_c0', 'usage_c1', 'usage_c2', 'usage_c3', \\\n",
    "            'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\\\n",
    "            'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu',\\\n",
    "            'freq_big_cluster', 'freq_little_cluster',\\\n",
    "            'volts_big_cluster', 'volts_little_cluster',\\\n",
    "            # Expected outputs:\n",
    "            'next_t4', 'next_t5', 'next_t6', 'next_t7', 'next_watts',\\\n",
    "            # Keep the timestamp for later plotting:\n",
    "            'time'\\\n",
    "            ]]\n",
    "XY.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVR regression model to predict each temperature (for big cores)\n",
    "# and power for the whole board:\n",
    "# The models:\n",
    "TPMs = []\n",
    "for i in range(5):\n",
    "    TPMs.append( svm.SVR() )\n",
    "X = XY[ [\n",
    "            # Inputs:\n",
    "            'watts', 'usage_c0', 'usage_c1', 'usage_c2', 'usage_c3', \\\n",
    "            'usage_c4', 'usage_c5', 'usage_c6', 'usage_c7',\\\n",
    "            'temp4', 'temp5', 'temp6', 'temp7', 'temp_gpu',\\\n",
    "            'freq_big_cluster', 'freq_little_cluster',\\\n",
    "            'volts_big_cluster', 'volts_little_cluster' ] ].as_matrix()\n",
    "\n",
    "Y = XY[ ['next_t4', 'next_t5', 'next_t6', 'next_t7', 'next_watts'] ].as_matrix()\n",
    "\n",
    "# # Create training and test sets:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training model 0\n",
      "Finished training model 1\n",
      "Finished training model 2\n",
      "Finished training model 3\n",
      "Finished training model 4\n"
     ]
    }
   ],
   "source": [
    "# Train the models:\n",
    "for i in range(5):\n",
    "    TPMs[i] = TPMs[i].fit(X_train, Y_train[:, i])\n",
    "    print(\"Finished training model {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pt = []#np.matrix()\n",
    "# Run each of the models on test data:\n",
    "Pt.append( TPMs[i].predict(X_train) )\n",
    "Pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P = []\n",
    "# Run each of the models on test data:\n",
    "P.append( TPM.predict(X_test) )\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score:\n",
    "R = TPM.score(X_test, np.as_matrix(P) )\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train - np.as_matrix(Pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
